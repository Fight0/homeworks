{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79583398-41f1-4dce-a51a-7bbc9b4d6bbc",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "\r\n",
    "Обучите нейронную сеть решать шифр Цезаря\n",
    "\n",
    "Что необходимо сделать:."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7fc76-b6e3-4ca1-8786-d1c5829cb2d1",
   "metadata": {},
   "source": [
    "1. Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)\n",
    "2. Сделать нейронную сеть\n",
    "3. Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)\n",
    "4. Проверить качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaff6939-d01d-4ec7-a8a8-da6c13d9c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00df2a4a-93eb-4525-81ee-67a57667b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры обучения\n",
    "K = 10\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f48ed6-aad8-496b-9028-05d88d2b8954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device=='cpu':\n",
    "  torch.manual_seed(SEED)\n",
    "else:\n",
    "  torch.cuda.manual_seed(SEED)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b55b44-ced6-4e06-9ea9-8dfdb20b1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters='абвгдежзийклмнопрстуфхцчшщъыьэюя '\n",
    "CHARS = list(all_letters)\n",
    "INDEX_TO_CHAR =[w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}\n",
    "n_letters = len(all_letters)\n",
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28a83a9-682c-4555-89a9-0fce9aeeda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_encrypt(text, k):\n",
    "    \"\"\"функция для шифрования текста с помощью шифра Цезаря.\n",
    "    Функция принимает на вход текст и параметр К (сдвиг), и возвращает зашифрованный текст\"\"\"\n",
    "    cipher_text = ''\n",
    "    for letter in text.lower():\n",
    "        if letter in CHARS:\n",
    "            index = (CHARS.index(letter) + k) % len(CHARS)\n",
    "            cipher_text += CHARS[index]\n",
    "        else:\n",
    "            cipher_text += letter\n",
    "    return cipher_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434ac1e4-6ae8-4b40-886d-e7e1a1c11193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зашифрованный текст: скбтюъшмкччдуйьпфыь\n"
     ]
    }
   ],
   "source": [
    "original_text = \"Зашифрованный текст\"\n",
    "ciphered_text = caesar_encrypt(original_text, K)\n",
    "print(\"Зашифрованный текст:\", ciphered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec425cdf-a797-4eae-9ffc-106eef508ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_decrypt(ciphertext, shift):\n",
    "    \"\"\"\n",
    "    Функция  дешифровки - справочно.\n",
    "    \"\"\"\n",
    "    plaintext = \"\"\n",
    "    for char in ciphertext:\n",
    "      i = INDEX_TO_CHAR.index(char)\n",
    "      j = i - shift\n",
    "      if j < 0:\n",
    "        j +=33\n",
    "      decrypted_char = INDEX_TO_CHAR[j]\n",
    "      plaintext += decrypted_char\n",
    "    return plaintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208099d7-6eec-4feb-b856-730c4a639628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зашифрованный текст: зашифрованный текст\n"
     ]
    }
   ],
   "source": [
    "decrypted_text = caesar_decrypt(ciphered_text, K)\n",
    "print(\"Зашифрованный текст:\", decrypted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad942b4e-fa8f-42b9-9927-de1fa9f00353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   алекс каменев (alex kamenev)\\n   макс вольф 2.\\n   наемник.\\n   глава 1.\\n   станция технического об'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(Path('data/Kamenev_Maks-Volf_2_Naemnik_RuLit_Me.txt'), 'r') as f1:\n",
    "    all_text = f1.read().lower()\n",
    "all_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62aeef0-0226-4be9-aa29-b4e3bbb34a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' то есть как заблокировали стыковочные захваты о ч',\n",
       " ' пять минут назад он вызвал меня по внутренней свя',\n",
       " ' видимо ролло не слишком мне доверял и установил о',\n",
       " ' подобное поведение раздражало хотя и вполне объяс',\n",
       " ' бандит боящийся угона своего корабля это что шутк',\n",
       " ' нет он действительно любил некроникс и похоже пос',\n",
       " ' не думал ты что не мог проконтролировать исходящи',\n",
       " ' знаешь что в содружестве делают с пиратами подхож',\n",
       " ' знаю не менее яростный ответ показывает что пилот',\n",
       " ' недовольно дернувшись логан сатон отсоединил линк',\n",
       " ' что можно сделать принудительная отстыковка',\n",
       " ' нет отрицательно качание головы в ответ корабль в',\n",
       " ' фиксирую движение у главного перехода с внешней с',\n",
       " ' а вот и ожил древний искин предтеч и как всегда с',\n",
       " ' капитан очевидность блин']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_sentences = all_text.split('\\n')\n",
    "# Удаляем все символы, кроме кириллицы и пробелов\n",
    "pattern = re.compile('[^а-я\\s]+')\n",
    "for i in range(len(plain_sentences)):\n",
    "    plain_sentences[i] = re.sub(pattern, '', plain_sentences[i])\n",
    "    plain_sentences[i].strip()\n",
    "# Заеменяем несколько подряд стоящих пробелов на 1\n",
    "pattern = re.compile('[\\s\\s]+')\n",
    "for i in range(len(plain_sentences)):\n",
    "    plain_sentences[i] = re.sub(pattern, ' ', plain_sentences[i])\n",
    "    plain_sentences[i].strip()\n",
    "\n",
    "plain_sentences = [x[:MAX_LEN] for x in plain_sentences if x != '']\n",
    "\n",
    "for i in range(len(plain_sentences)):\n",
    "    plain_sentences[i].strip()\n",
    "\n",
    "plain_sentences[5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c1dc59-a3ce-4bc4-8459-b5e1a94452f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plain_sentences, test_plain_sentences = train_test_split(plain_sentences, test_size=0.2, random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f127ae-b51e-4383-9853-1cbf2795b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cypher(plain_sentences, K):\n",
    "  \n",
    "  cypher_sentences = []\n",
    "  \n",
    "  for item in plain_sentences:\n",
    "    cypher_sentences.append(caesar_encrypt(item, K))\n",
    "  return cypher_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fdd44bd-b814-4a53-b5cc-eb067cc8bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cypher_sentences = make_cypher(train_plain_sentences, K)\n",
    "test_cypher_sentences = make_cypher(test_plain_sentences, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e7aa740-41ca-4c78-8e84-e75713334f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, sentences, state=None):\n",
    "        x = self.embedding(sentences)\n",
    "        x, s = self.rnn(x) \n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc0c34a-2034-432c-867e-0747fd6d3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_length):\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) < max_length:\n",
    "            padded_sequence = sequence + [0] * (max_length - len(sequence))\n",
    "        else:\n",
    "            padded_sequence = sequence[:max_length]\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42628d3e-fce8-4236-b74b-db5d4b7e55b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3000, 50]), torch.Size([3000, 50]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor(pad_sequences([[CHAR_TO_INDEX[symb] for symb in line] for line in train_cypher_sentences], MAX_LEN)).long().to(device)\n",
    "Y = torch.Tensor(pad_sequences([[CHAR_TO_INDEX[symb] for symb in line] for line in train_plain_sentences], MAX_LEN)).long().to(device)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf9eae78-fa1e-4aaf-be1e-5a138aef9a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3000, 50]), torch.Size([3000, 50]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.Tensor(pad_sequences([[CHAR_TO_INDEX[symb] for symb in line] for line in test_cypher_sentences], MAX_LEN)).long().to(device)\n",
    "Y_test = torch.Tensor(pad_sequences([[CHAR_TO_INDEX[symb] for symb in line] for line in test_plain_sentences], MAX_LEN)).long().to(device)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08ed529c-37f7-48f2-9bbc-e5380e521af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, criterion):\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for sentences, targets in data:\n",
    "            output = model(sentences)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912152ca-de24-41f8-97fa-6c050ca77732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for sentences, targets in data:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(sentences.to(device))\n",
    "            loss = criterion(output.view(-1, output.size(-1)), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if (epoch) % 10 == 0 or epoch == 1:\n",
    "            model.eval()\n",
    "            test_loss = evaluate_model(model, test_data, criterion)\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], train_loss: {running_loss/len(data)}, test_loss:{test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f82e627b-f8f6-490e-95c9-90f6fad4374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "data = [(X[i:i+batch_size], Y[i:i+batch_size]) for i in range(0, len(X), batch_size)]\n",
    "test_data = [(X_test[i:i+batch_size], Y_test[i:i+batch_size]) for i in range(0, len(X_test), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e86f1bf7-3075-4a8b-80a7-3ce8a0e6f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], train_loss: 3.613961478074392, test_loss:3.129843235015869\n",
      "Epoch [10/100], train_loss: 0.20259022091825804, test_loss:0.1792769432067871\n",
      "Epoch [20/100], train_loss: 0.06362259605278571, test_loss:0.06278398384650548\n",
      "Epoch [30/100], train_loss: 0.045376332476735115, test_loss:0.04604950671394666\n",
      "Epoch [40/100], train_loss: 0.03932228498160839, test_loss:0.04025315120816231\n",
      "Epoch [50/100], train_loss: 0.03641301734993855, test_loss:0.037379718075195946\n",
      "Epoch [60/100], train_loss: 0.034736888172725834, test_loss:0.03567769502600034\n",
      "Epoch [70/100], train_loss: 0.03366351996858915, test_loss:0.03457572807868322\n",
      "Epoch [80/100], train_loss: 0.03292670954639713, test_loss:0.03383045891920725\n",
      "Epoch [90/100], train_loss: 0.0323892078983287, test_loss:0.03330995887517929\n",
      "Epoch [100/100], train_loss: 0.03197170173128446, test_loss:0.03293973455826441\n"
     ]
    }
   ],
   "source": [
    "model = RNN(MAX_LEN, 64, MAX_LEN).to(device)\n",
    "\n",
    "# Определение критерия и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, data, criterion, optimizer, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d574f155-5b98-468a-91b0-dca7cbc164b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sentence):\n",
    "    all_indices = []\n",
    "    model.eval()\n",
    "\n",
    "    for line in sentence:\n",
    "        for s in line:\n",
    "            s = torch.Tensor(pad_sequences([[CHAR_TO_INDEX[symb] for symb in line] for line in s], MAX_LEN)).long().to(device)\n",
    "    \n",
    "            # Передаем в модель тензор категорий, тензор для текущей буквы в шифровке и скрытое состояние\n",
    "            output = model(s)\n",
    "    \n",
    "            # Получаем индекс наиболее вероятной буквы при расшифровке с использованием данного сдвига (категории)\n",
    "            probas, indices = output.topk(1)\n",
    "    \n",
    "            # Собираем все индексы  -  по каждой букве - в один список\n",
    "            all_indices.append(indices.flatten().cpu().numpy()[0])\n",
    "            \n",
    "    # преобразуем индексы букв в сами буквы и получаем расшифровку\n",
    "    result = ''.join(INDEX_TO_CHAR[i] for i in all_indices)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d780a450-7032-4bab-9c30-13ca96bb7af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['щътмпьй', 'цтъй', 'жьшй', 'цшуй', 'щпъмдуй', 'фшо']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['Привет ', 'мир ', 'Это ', 'мой ', 'первый ', 'код']\n",
    "ciphered_text = [caesar_encrypt(original_text, K) for original_text in corpus]\n",
    "\n",
    "ciphered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0cbfa39-f84b-4e7b-a0d4-7050a2751eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'привет мир это мой первый код'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(ciphered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174afa89-6cac-40a9-9986-91f9607a05ff",
   "metadata": {},
   "source": [
    "## Задание 2.\r\n",
    "Выполнить практическую работу из лекционного ноутбука."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0af271-1856-4fcd-8778-2ba73c22df56",
   "metadata": {},
   "source": [
    "1. Построить RNN-ячейку на основе полносвязных слоев.\n",
    "2. Применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "674f591d-5b9e-49fc-b828-c51368072c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6f6f2d0-f741-47a9-aef2-261e425f32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2words(doc):\n",
    "  # мешок слов\n",
    "    words=[]\n",
    "    for line in doc:\n",
    "      words += line.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48faa1d8-6d1c-4454-81f6-b56890e0e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removepunct(words):\n",
    "  # Удаляем пунктуацию\n",
    "    punct = set(string.punctuation)\n",
    "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cf2c331-8fe7-4036-b2b0-871add0f0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(words):\n",
    "  # Словарь из мешка слов\n",
    "    wordfreq = Counter(words)\n",
    "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
    "    return sorted_wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "019767e7-77ea-4514-a345-8e65143a8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_map(vocab):\n",
    "    # 2 словаря - int to words and word to int\n",
    "    int_to_vocab = {k:w for k,w in enumerate(vocab)}\n",
    "    vocab_to_int = {w:k for k,w in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caa999ee-fb82-4a2e-a351-6c1d7278318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(words, vocab_to_int, batch_size, seq_size):\n",
    "    # Генерируем батчи для  Xs и Ys: shape = (batchsize * num_batches) * seq_size\n",
    "    word_ints = [vocab_to_int[word] for word in words]\n",
    "    num_batches = int(len(word_ints) / (batch_size * seq_size))\n",
    "    Xs = word_ints[:num_batches*batch_size*seq_size]\n",
    "    Ys = np.zeros_like(Xs)\n",
    "    Ys[:-1] = Xs[1:]\n",
    "    Ys[-1] = Xs[0]\n",
    "    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n",
    "    Ys = np.reshape(Ys, (num_batches*batch_size, seq_size))\n",
    "    \n",
    "    for i in range(0, num_batches*batch_size, batch_size):\n",
    "        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95202dcd-c245-4178-9fc8-ee51f31ed2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "\n",
    "    def __init__(self, n_vocab, seq_size=32, embedding_size=64, lstm_size=32):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45c6f82a-5449-486e-8be0-7c0c1d1c138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_train_op(net, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feac7fc1-7192-4aa5-8db3-a23f2941535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fbed84a-3f5b-4ea6-9153-43283c315071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(words, vocab_to_int, int_to_vocab, n_vocab):\n",
    "    \n",
    "    # ячейка RNN\n",
    "    net = RNNModule(n_vocab, 32, 64, 64)\n",
    "    net = net.to(device)\n",
    "    criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    # итерируемся по эпохам\n",
    "    for e in tqdm(range(5)):\n",
    "        # получаем батчи\n",
    "        batches = get_batches(words, vocab_to_int, 32, 32)\n",
    "        # инициализируем выход и сккрытое состояние\n",
    "        state_h, state_c = net.zero_state(32)\n",
    "\n",
    "        # Передаем данные на GPU\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        # итерируемся по батчам\n",
    "        for x, y in tqdm(batches):\n",
    "            iteration += 1\n",
    "\n",
    "            # Переходим  в режим обучения\n",
    "            net.train()\n",
    "\n",
    "            # Обнуляем градиенты\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Передаем x и y на GPU\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "            \n",
    "            # Модель возвращает логиты, последнее скрытое состояние и новый выход\n",
    "            logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y.long())\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            # back-propagation\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            _ = torch.nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
    "            \n",
    "            # Обновляем параметры, выполняя шаг обучения\n",
    "            optimizer.step()\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                print('Epoch: {}/{}'.format(e, 200),'Iteration: {}'.format(iteration),'Loss: {}'.format(loss_value))\n",
    "\n",
    "            # if iteration % 1000 == 0:\n",
    "                # predict(device, net, flags.initial_words, n_vocab,vocab_to_int, int_to_vocab, top_k=5)\n",
    "                # torch.save(net.state_dict(),'checkpoint_pt/model-{}.pth'.format(iteration))\n",
    "                \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d801442-1756-44f2-8696-492e4a26b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no actually it was a little of both sometimes when a disease is in all the magazines and all the news shows its only natural that you think you have it',\n",
       " 'wheres mr bergstrom',\n",
       " 'i dont know although id sure like to talk to him he didnt touch my lesson plan what did he teach you',\n",
       " 'that life is worth living',\n",
       " 'the polls will be open from now until the end of recess now just in case any of you have decided to put any thought into this well have our final statements martin']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.read_csv('data/simpsons_script_lines.csv', usecols=['normalized_text'],low_memory=False)['normalized_text'].astype(str).to_list()\n",
    "doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f303f797-d3f7-4999-b7d6-2c50eadb188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка\n",
    "words = removepunct(doc2words(doc))\n",
    "vocab = getvocab(words)\n",
    "int_to_vocab, vocab_to_int = vocab_map(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1ec5632-e597-4331-8dc4-b2f7634c6706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5883e0ac175463c81ce7f0e25bcc58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6feb8f96384dcea71cf2a62474af57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200 Iteration: 100 Loss: 6.783677101135254\n",
      "Epoch: 0/200 Iteration: 200 Loss: 6.454249382019043\n",
      "Epoch: 0/200 Iteration: 300 Loss: 6.178114891052246\n",
      "Epoch: 0/200 Iteration: 400 Loss: 6.626694202423096\n",
      "Epoch: 0/200 Iteration: 500 Loss: 6.342596054077148\n",
      "Epoch: 0/200 Iteration: 600 Loss: 6.122922897338867\n",
      "Epoch: 0/200 Iteration: 700 Loss: 6.010077953338623\n",
      "Epoch: 0/200 Iteration: 800 Loss: 6.387012004852295\n",
      "Epoch: 0/200 Iteration: 900 Loss: 5.8750481605529785\n",
      "Epoch: 0/200 Iteration: 1000 Loss: 6.584317684173584\n",
      "Epoch: 0/200 Iteration: 1100 Loss: 6.211277484893799\n",
      "Epoch: 0/200 Iteration: 1200 Loss: 6.405735969543457\n",
      "Epoch: 0/200 Iteration: 1300 Loss: 6.00385046005249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e39c4dc0ad4b8b9cf05e7cb091a9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200 Iteration: 1400 Loss: 5.719114780426025\n",
      "Epoch: 1/200 Iteration: 1500 Loss: 5.99172830581665\n",
      "Epoch: 1/200 Iteration: 1600 Loss: 5.833299160003662\n",
      "Epoch: 1/200 Iteration: 1700 Loss: 5.675997734069824\n",
      "Epoch: 1/200 Iteration: 1800 Loss: 5.862273216247559\n",
      "Epoch: 1/200 Iteration: 1900 Loss: 5.9734272956848145\n",
      "Epoch: 1/200 Iteration: 2000 Loss: 5.61801815032959\n",
      "Epoch: 1/200 Iteration: 2100 Loss: 5.313600063323975\n",
      "Epoch: 1/200 Iteration: 2200 Loss: 5.647763729095459\n",
      "Epoch: 1/200 Iteration: 2300 Loss: 5.71717643737793\n",
      "Epoch: 1/200 Iteration: 2400 Loss: 5.839413166046143\n",
      "Epoch: 1/200 Iteration: 2500 Loss: 5.418987274169922\n",
      "Epoch: 1/200 Iteration: 2600 Loss: 5.562053203582764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e0106c08f4074afbfa394121ff163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/200 Iteration: 2700 Loss: 5.683876991271973\n",
      "Epoch: 2/200 Iteration: 2800 Loss: 5.37455415725708\n",
      "Epoch: 2/200 Iteration: 2900 Loss: 5.4336442947387695\n",
      "Epoch: 2/200 Iteration: 3000 Loss: 5.437780857086182\n",
      "Epoch: 2/200 Iteration: 3100 Loss: 5.489935398101807\n",
      "Epoch: 2/200 Iteration: 3200 Loss: 5.647677898406982\n",
      "Epoch: 2/200 Iteration: 3300 Loss: 5.664626598358154\n",
      "Epoch: 2/200 Iteration: 3400 Loss: 5.139298915863037\n",
      "Epoch: 2/200 Iteration: 3500 Loss: 5.526797771453857\n",
      "Epoch: 2/200 Iteration: 3600 Loss: 5.244123935699463\n",
      "Epoch: 2/200 Iteration: 3700 Loss: 5.480949878692627\n",
      "Epoch: 2/200 Iteration: 3800 Loss: 5.358027935028076\n",
      "Epoch: 2/200 Iteration: 3900 Loss: 5.541860103607178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7a9895f30e4e728956b8692a3ec71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/200 Iteration: 4000 Loss: 5.370248317718506\n",
      "Epoch: 3/200 Iteration: 4100 Loss: 5.236973762512207\n",
      "Epoch: 3/200 Iteration: 4200 Loss: 5.312046527862549\n",
      "Epoch: 3/200 Iteration: 4300 Loss: 5.391300201416016\n",
      "Epoch: 3/200 Iteration: 4400 Loss: 5.438663482666016\n",
      "Epoch: 3/200 Iteration: 4500 Loss: 5.197635173797607\n",
      "Epoch: 3/200 Iteration: 4600 Loss: 5.533201694488525\n",
      "Epoch: 3/200 Iteration: 4700 Loss: 5.294881820678711\n",
      "Epoch: 3/200 Iteration: 4800 Loss: 5.259171962738037\n",
      "Epoch: 3/200 Iteration: 4900 Loss: 5.44784688949585\n",
      "Epoch: 3/200 Iteration: 5000 Loss: 5.521522045135498\n",
      "Epoch: 3/200 Iteration: 5100 Loss: 5.545651912689209\n",
      "Epoch: 3/200 Iteration: 5200 Loss: 5.349438667297363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b91dc0765346a9b7ca82140d4d8b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/200 Iteration: 5300 Loss: 5.264430999755859\n",
      "Epoch: 4/200 Iteration: 5400 Loss: 5.356697082519531\n",
      "Epoch: 4/200 Iteration: 5500 Loss: 5.2102251052856445\n",
      "Epoch: 4/200 Iteration: 5600 Loss: 5.366838455200195\n",
      "Epoch: 4/200 Iteration: 5700 Loss: 5.170050621032715\n",
      "Epoch: 4/200 Iteration: 5800 Loss: 5.330789089202881\n",
      "Epoch: 4/200 Iteration: 5900 Loss: 5.033596515655518\n",
      "Epoch: 4/200 Iteration: 6000 Loss: 5.226826190948486\n",
      "Epoch: 4/200 Iteration: 6100 Loss: 5.091064929962158\n",
      "Epoch: 4/200 Iteration: 6200 Loss: 5.061532497406006\n",
      "Epoch: 4/200 Iteration: 6300 Loss: 5.26991605758667\n",
      "Epoch: 4/200 Iteration: 6400 Loss: 5.2263994216918945\n",
      "Epoch: 4/200 Iteration: 6500 Loss: 5.263146877288818\n"
     ]
    }
   ],
   "source": [
    "rnn_net = train_rnn(words, vocab_to_int, int_to_vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c6d70f0-c5a9-4599-b2bf-dd2c46b23501",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn_net.state_dict(), 'rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cb9469e-5f7e-4578-95a2-f5ffdbabcef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey you know i want you i want the money nan i cant get the money to you i think that were you gonna get to you nan oh my little league nan hey homer i think youre right i know you want me right to me you dont know i dont want to get a few boners i want a big kid you have you to tell you about it nan hello i dont know i know you have a big man i want a big kid who is the greatest day to make you have the way you ever want you\n"
     ]
    }
   ],
   "source": [
    "generate_txt(device, rnn_net, ['hey', 'you'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
