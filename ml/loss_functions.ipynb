{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f932ab",
   "metadata": {},
   "source": [
    "**Задание**\n",
    "\n",
    "**Цель:** \n",
    "Изучить применение методов оптимизации для решения задачи классификации.\n",
    "\n",
    "**Описание задания:**\n",
    "В домашнем задании необходимо применить полученные знания в теории оптимизации и машинном обучении для реализации логистической регрессии.\n",
    "\n",
    "**Этапы работы:**\n",
    "\n",
    "1)Загрузите данные. Используйте [датасет](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) с ирисами. Его можно загрузить непосредственно из библиотеки Sklearn. В данных оставьте только 2 класса: Iris Versicolor, Iris Virginica.\n",
    "\n",
    "2)Самостоятельно реализуйте логистическую регрессию, без использования метода LogisticRegression из библиотеки. Можете использовать библиотеки pandas, numpy, math для реализации. Оформите в виде функции. Оформите в виде класса с методами.\n",
    "\n",
    "3)Реализуйте метод градиентного спуска. Обучите логистическую регрессию этим методом. Выберете и посчитайте метрику качества. Метрика должна быть одинакова для всех пунктов домашнего задания. Для упрощения сравнения выберете только одну метрику.\n",
    "\n",
    "4)Повторите п. 3 для метода скользящего среднего (Root Mean Square Propagation, RMSProp).\n",
    "\n",
    "5)Повторите п. 3 для ускоренного по Нестерову метода адаптивной оценки моментов (Nesterov–accelerated Adaptive Moment Estimation, Nadam).\n",
    "\n",
    "6)Сравните значение метрик для реализованных методов оптимизации. Можно оформить в виде таблицы вида |метод|метрика|время работы| (время работы опционально). Напишите вывод.\n",
    "\n",
    "Для лучшего понимания темы и упрощения реализации можете обратиться к [статье](https://habr.com/en/post/318970/).\n",
    "\n",
    "Для получение зачета по этому домашнему заданию, минимально, должно быть реализовано обучение логистической регрессии и градиентный спуск.\n",
    "\n",
    "**Результат:** получены навыки реализации методов оптимизации в задаче бинарной классификации. Пройденные методы оптимизации используются и в нейросетях.\n",
    "\n",
    "**Форма выполнения:** ссылка на Jupyter Notebook, загруженный на GitHub; ссылка на Google Colab; файл с расширением .ipynb.\n",
    "\n",
    "**Инструменты:** Jupyter Notebook/Google Colab; GitHub.\n",
    "\n",
    "**Рекомендации к выполнению:**\n",
    "\n",
    "• Текст оформляйте в отдельной ячейке Jupyter Notebook/Google Colab в формате markdown.\n",
    "\n",
    "• У графиков должен быть заголовок, подписи осей, легенда (опционально). Делайте графики бОльшего размера, чем стандартный вывод, чтобы увеличить читаемость.\n",
    "\n",
    "• Убедитесь, что по ссылкам есть доступ на чтение/просмотр.\n",
    "\n",
    "• Убедитесь, что все ячейки в работе выполнены и можно увидеть их вывод без повторного запуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9539a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168df0a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "50                7.0               3.2                4.7               1.4   \n",
       "51                6.4               3.2                4.5               1.5   \n",
       "52                6.9               3.1                4.9               1.5   \n",
       "53                5.5               2.3                4.0               1.3   \n",
       "54                6.5               2.8                4.6               1.5   \n",
       "\n",
       "    target  \n",
       "50       1  \n",
       "51       1  \n",
       "52       1  \n",
       "53       1  \n",
       "54       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(load_iris(as_frame=True).data)\n",
    "df['target'] = load_iris().target\n",
    "df = df.loc[df.target != 0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17f6467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4),\n",
       " 50     0\n",
       " 51     0\n",
       " 52     0\n",
       " 53     0\n",
       " 54     0\n",
       "       ..\n",
       " 145    1\n",
       " 146    1\n",
       " 147    1\n",
       " 148    1\n",
       " 149    1\n",
       " Name: target, Length: 100, dtype: int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']], df['target']\n",
    "y -= 1\n",
    "X.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901529b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self, iterations=250, learning_rate=0.01, eps = 0.007, epsilon=1e-30):\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = eps\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def data_prep(self, X, y):\n",
    "        '''Предобработка данных'''\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        self.X = scaler.fit_transform(X)\n",
    "        # добавляем столбец из единиц для работы со свободными весами\n",
    "        self.X = np.c_[np.ones(len(self.X)), self.X]\n",
    "        self.y = y\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        '''Функция сигмоиды'''\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def loop_exit(self, cur_W):\n",
    "        '''Проверка достиждения необходимой степени точности'''\n",
    "        if np.linalg.norm(cur_W - self.next_W) <= self.eps:\n",
    "            return True\n",
    "    \n",
    "    def logloss(self):\n",
    "        '''Функция потерь Logloss'''\n",
    "        l_loss0 = np.sum(np.log(1 - self.y_proba[self.y == 0]) + self.epsilon)\n",
    "        l_loss1 = np.sum(np.log(self.y_proba[self.y == 1]) + self.epsilon)\n",
    "        return -(l_loss0 + l_loss1)/len(self.y)\n",
    "        \n",
    "    def grad(self):\n",
    "        '''Градиент'''\n",
    "        grad = self.X.T @ (self.y_proba - self.y)\n",
    "        return grad\n",
    "    \n",
    "    def start_weights(self):\n",
    "        '''Cтартовые веса'''\n",
    "        np.random.seed(42)\n",
    "        self.weights = np.random.randn(self.X.shape[1])\n",
    "        return self.weights\n",
    "    \n",
    "    def gradient_descent(self):        \n",
    "        '''Градиентный спуск'''\n",
    "        \n",
    "        self.next_W = self.start_weights()       \n",
    "        for i in range(self.iterations):\n",
    "            cur_W = self.next_W\n",
    "            \n",
    "            self.y_proba = self.sigmoid(self.X @ self.next_W)\n",
    "            # движение в негативную сторону вычисляемого градиента\n",
    "            self.next_W = cur_W - self.learning_rate * self.grad()\n",
    "            \n",
    "            if self.loop_exit(cur_W):\n",
    "                break\n",
    "        \n",
    "        y_class = np.where(self.y_proba >= 0.5, 1, 0)\n",
    "        accuracy = (y_class == y).sum() / len(y)\n",
    "        print(f\"Всего {i+1} итераций\")\n",
    "        print(f\"Logloss {self.logloss()}\")\n",
    "        print(f\"Accuracy {accuracy}\")\n",
    "                \n",
    "    def RMSProp(self, decay_rate=0.9):\n",
    "        '''Среднеквадратичное распространение корня'''\n",
    "        \n",
    "        self.next_W = self.start_weights()\n",
    "        grad_squared = np.zeros_like(self.next_W)\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            cur_W = self.next_W\n",
    "            \n",
    "            self.y_proba = self.sigmoid(self.X @ self.next_W)\n",
    "            # вычисление квадрата градиента\n",
    "            grad_squared = decay_rate * grad_squared + (1 - decay_rate) * np.square(self.grad())\n",
    "            # вычисление новых весов\n",
    "            self.next_W = cur_W - self.learning_rate * self.grad() / (np.sqrt(grad_squared) + self.epsilon)\n",
    "            \n",
    "            if self.loop_exit(cur_W):\n",
    "                break\n",
    "        \n",
    "        y_class = np.where(self.y_proba >= 0.5, 1, 0)\n",
    "        accuracy = (y_class == self.y).sum() / len(self.y)\n",
    "        print(f\"Всего {i+1} итераций\")\n",
    "        print(f\"Accuracy {accuracy}\")\n",
    "        \n",
    "    def nadam(self, beta_1=0.9, beta_2=0.999):        \n",
    "        '''Nesterov-accelerated adaptive momentum'''\n",
    "        \n",
    "        m_t = np.zeros(self.weights.shape)\n",
    "        v_t = np.zeros(self.weights.shape)\n",
    "        self.next_W = self.start_weights()\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            cur_W = self.next_W\n",
    "            \n",
    "            self.y_proba = self.sigmoid(self.X @ self.next_W)\n",
    "            # обновляем первый и второй моменты\n",
    "            m_t = beta_1*m_t + (1-beta_1)*self.grad()\n",
    "            v_t = beta_2*v_t + (1-beta_2)*self.grad()**2\n",
    "            # исправляем смещение\n",
    "            m_t_hat = m_t / (1 - beta_1**(i+1))\n",
    "            v_t_hat = v_t / (1 - beta_2**(i+1))\n",
    "            # вычисляем коррекционный коэффициент\n",
    "            n_correction = self.learning_rate / (np.sqrt(v_t_hat) + self.epsilon)\n",
    "            # вычисляем следующую точку\n",
    "            self.next_W = cur_W - n_correction * (beta_1*m_t_hat + (1-beta_1)*self.grad()) \n",
    "            \n",
    "            if self.loop_exit(cur_W):\n",
    "                break\n",
    "        \n",
    "        y_class = np.where(self.y_proba >= 0.5, 1, 0)\n",
    "        accuracy = (y_class == self.y).sum() / len(self.y)\n",
    "        print(f\"Всего {i+1} итераций\")\n",
    "        print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a368cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9cda0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.data_prep(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "162b0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 230 итераций\n",
      "Logloss 0.07128996304462287\n",
      "Accuracy 0.97\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 45.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.gradient_descent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a7fdda5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 250 итераций\n",
      "Accuracy 0.99\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 85.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.RMSProp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e6c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 218 итераций\n",
      "Accuracy 0.99\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.nadam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4044b31",
   "metadata": {},
   "source": [
    "Градиентный спуск дал чуть худшее значение метрики **accuracy** - **0.97**. При этом время работы оптимизатора минимально.\n",
    "\n",
    "Применение **RMSProp** и **Nadam** позволило получить чуть лучшее значение - **0.99**. Время работы алгоритма **RMSProp** почти в 2 раза меньше, чем у **Nadam**, несмотря на большее число итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e26ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
